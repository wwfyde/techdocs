 

# 操作系统

> 《深入理解计算机系统》--纸质书
>
> 《操作系统》--上海交大

常见问题:

了解应用是如何与硬件交互;

异常控制流: 应用是如何与操作系统交互的;

## 参考资料

- 《深入理解计算机系统》





# 基本概念

## 通用

- 句柄(handle): 在英文中，有操作、处理、控制之类的意义。作为一个名词时，是指某个中间媒介，通过这个中间媒介可控制、操作某样东西。一串数字, 对某个对象进行操作时的标识。 能够标识对象的最简单表示法。句柄就是个数字，一般和当前系统下的整数的位数一样，比如32bit系统下就是4个字节。
  这个数字是一个对象的唯一标示，和对象一一对应。
  这个对象可以是一个块内存，一个资源，或者一个服务的context（如 socket，thread）等等。
  - A handle of any sentential form is a leftmost simple phrase.
  - 任一句型的句柄就是此句型的最左简单短语。
- 时间戳(timestamp): 

## 幂等性

**幂等性**原本是数学上的概念，即使公式：f(x)=f(f(x)) 能够成立的数学性质。

用在编程领域，则意为 <u>对同一个系统，使用同样的条件，一次请求和重复的多次请求对系统资源的影响是一致的。</u>

幂等性：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品使用约支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条．．．

在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等等。

## 状态机- State Machine



> 一种数学模型
>
> 参考文档:
>
> [有限状态机知乎](https://zhuanlan.zhihu.com/p/47434856#:~:text=%E6%88%91%E4%BB%AC%E9%80%9A%E5%B8%B8%E6%89%80%E8%AF%B4%E7%9A%84,%E5%87%BA%E4%B8%8B%E9%9D%A2%E8%BF%99%E4%B9%88%E4%B8%80%E4%B8%AA%E5%9B%BE%E3%80%82)
>
> [JavaScript状态机](https://github.com/jakesgordon/javascript-state-machine)
>
> [有限状态机维基](https://zh.wikipedia.org/wiki/%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA)

```js
var fsm = new StateMachine({
    init: 'solid',
    transitions: [
      { name: 'melt',     from: 'solid',  to: 'liquid' },
      { name: 'freeze',   from: 'liquid', to: 'solid'  },
      { name: 'vaporize', from: 'liquid', to: 'gas'    },
      { name: 'condense', from: 'gas',    to: 'liquid' }
    ],
    methods: {
      onMelt:     function() { console.log('I melted')    },
      onFreeze:   function() { console.log('I froze')     },
      onVaporize: function() { console.log('I vaporized') },
      onCondense: function() { console.log('I condensed') }
    }
  });
```

状态(stae): 状态标识符, 初始状态等.

事件(event): 一个方法对象. 

转移(状态转移, transition): 输入状态到输出状态的映射;

自循环: 同一个输入和输出状态之间的转移.

一个状态从某种输入状态开始执行. 

每个输入事件都会引发一个从当前状态到下一个状态的转移.

```
状态机的四大概念


State-状态:一个状态机至少要包含两个状态。
	例如自动门有 open 和 closed 两个状态。
Event-事件:事件就是执行某个操作的触发条件或者口令。
	对于自动门，“按下开门按钮”就是一个事件。
Action-动作:事件发生以后要执行动作。
	例如事件是“按开门按钮”，动作是“开门”。编程的时候，一个 Action一般就对应一个函数。
Transition-变换: 也就是从一个状态变化为另一个状态。例如“开门过程”就是一个变换。
```

## 文件描述符(File descriptor)

>  文件描述符相当于一个指针 指向打开的文件, 可以通过文件描述符访问该文件

用于表述指向[文件](https://zh.wikipedia.org/wiki/文件)的引用的抽象化概念。

文件描述符是一个数字, 用来表示的操作系统中已打开文件的唯一标识符. 它描述了一个数据源, 通过该句柄对资源进行存取和访问.

<u>一个用于存取/访问(access)文件或输入输出流的抽象指示符(句柄 handle)</u>

```text
A file descriptor is a number that uniquely identifies an open file in a computer's operating system. It describes a data resource, and how that resource may be accessed.

```





文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向[内核](https://zh.wikipedia.org/wiki/内核)为每一个[进程](https://zh.wikipedia.org/wiki/进程)所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。

在[程序设计](https://zh.wikipedia.org/wiki/程序设计)中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于[UNIX](https://zh.wikipedia.org/wiki/UNIX)、[Linux](https://zh.wikipedia.org/wiki/Linux)这样的操作系统。

每个Unix进程（除了可能的[守护进程](https://zh.wikipedia.org/wiki/守护进程)）应均有三个标准的[POSIX](https://zh.wikipedia.org/wiki/POSIX)文件描述符，对应于三个标准流：

| 整数值 |                          名称                           | unistd.h符号常量 | stdio.h文件流 |
| :----: | :-----------------------------------------------------: | :--------------: | :-----------: |
|   0    |  [Standard input](https://zh.wikipedia.org/wiki/Stdin)  |   STDIN_FILENO   |     stdin     |
|   1    | [Standard output](https://zh.wikipedia.org/wiki/Stdout) |  STDOUT_FILENO   |    stdout     |
|   2    | [Standard error](https://zh.wikipedia.org/wiki/Stderr)  |  STDERR_FILENO   |    stderr     |

文件描述符的优点主要有两个：

- 基于文件描述符的[I/O操作](https://zh.wikipedia.org/wiki/I/O)兼容[POSIX](https://zh.wikipedia.org/wiki/POSIX)标准。
- 在UNIX、Linux的系统调用中，大量的系统调用都是依赖于文件描述符。



## 粒度-

粒度是指每个逻辑流每个时间片执行的指令数量. 

## 内核-kernel: 



# **计算机系统概论**

## 研究问题

**问题求解**, 计算机系统基础, 应用开发基础, 软件工程 四大模块

从程序员的角度来写的本书, 讲述应用程序员如何能够利用系统知识来编写更好的程序

Linux操作系统上运行C语言程序

程序的生命周期

数据的表示

## 信息: 数据表示

信息就是位 + 上下文 *序列+上下文*

- *上下文* - context: 语境, 语意, 情景. 
  - 起始 - 序列 - 结束 , 
  - 指定了开始和结束的序列, 指定了开始和长度的序列
  - 读取数据的方式, 
  - 处理一个数据对象时, 采取特定的格式或方法, 以读取该数据所携带的信息, 并对其进行一系列的处理
  - 区分不同数据对象的唯一方法是我们读到这些数据时的上下文. *该序列的含义, 数据类型, 解析规则等*

### 基本规则

- 文本的最小单元是字符

### ASCII码

> ASCII码规定计算机的首位表示数值的正负性

标准ASCII码字符集总共的编码有128个，包括32个通用控制符，10个十进制数码，52个英文大小写字母和34个专用符号7a686964616fe78988e69d8331333431366263。 

ASCII码的长度呢是一个字节，共8位，理论上可以表示256个字符，但是许多时候只谈128个，其原因是这样的： 

在计算机中，数字和字符本来是不加区分的。一个ACSII码在机器中，可能是字符，也可能做数字使用。为了兼顾这两种用途，也为了操作方便，规定ASCII码都是正的（正数）。在计算机内数值表示规定中，第一位是符号位，该位为*1表示负值*，*0表示正直*。这样还有7位可以用于编码，于是就有128个。后来，为了纳入更多的字符，就把第一位也用上了，成了“扩展ASCII”又有128个，这些值都是负的了。



### UTF-8

UTF-8是一种*变长字节编码方式*。对于某一个字符的UTF-8编码，如果只有一个字节则其最高二进制位为0；如果是多字节，其第一个字节从最高位开始，连续的二进制位值为1的个数决定了其编码的位数，其余各字节均以10开头。UTF-8最多可用到6个字节。

1字节 0xxxxxxx
2字节 110xxxxx 10xxxxxx
3字节 1110xxxx 10xxxxxx 10xxxxxx
4字节 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
5字节 111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx
6字节 1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx

1字节 : 2^7^ = 128 位, 首位是字节长度标识符

2字节 : 2^5+6^ = 2^11^ = 2048

3字节 : 2^4+6+6^ = 2^16^ = 65536





`Unicode` 与 `UTF-8` 的区别

- Unicode 是「[字符集](#unicode)」
- UTF-8 是「*编码规则*」

- *<a name='unicode'>字符集</a>*：为每一个「字符」分配一个唯一的 ID（学名为码位 / 码点 / Code Point）
- 编码规则：将「码位」转换为字节序列的规则（编码/解码 可以理解为 加密/解密 的过程）

## 编译系统

源程序(hello.c)通过**预处理器**编译成程序文本(hello.i), 然后经过**编译器**编译成汇编程序(hello.s), 经过**汇编器**编译成可重定位目标程序(hello.o), 经过**链接器**编译成可执行目标程序(hello, hello.exe)





- 理解编译系统地好处
    - 优化程序性能.
    - 理解链接时出现的错误.
    - 避免安全漏洞. 多年来, 缓存区溢出错误是造成大多数网络和Internet服务器上安全漏洞的主要原因.

## 操作系统管理硬件

> 文件是对I/O设备的抽象表示.
>
> 虚拟内存是对主存和磁盘I/O设备的抽象表示
>
> 进程是对处理器、主存和I/O设备的抽象表示
>
> 虚拟机是对整个计算机的抽象表示, 包括操作系统, 处理器和程序



### 进程

> 进程是资源分配的最小单位，线程是cpu调度的最小单位

进程时操作系统对一个正在运行的程序的一种抽象. 

### 线程

> 进程是资源分配的最小单位，线程是cpu调度的最小单位

一个进程实际上可以由多个称为线程的执行单元组成, 每个线程都运行在进程的上下文中, 并共享同样的代码和全局数据. 由于网络服务器中对并行处理的需求, 线程成为越来越重要的编程模型, 因为多线程之间比多进程之间更容易共享数据, 也因为线程一般来说都比进程更高效. 当有多处理器可用的时候, 多线程也是一种使得程序可以运行得更快的方法.

### 协程

线程进程都是同步机制，而协程则是异步。

协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态。

线程是抢占式，而协程是非抢占式的，所以需要用户自己释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。

协程并不是取代线程, 而且抽象于线程之上, 线程是被分割的CPU资源, 协程是组织好的代码流程, 协程需要线程来承载运行, 线程是协程的资源, 但协程不会直接使用线程, 协程直接利用的是执行器(Interceptor), 执行器可以关联任意线程或线程池, 可以使当前线程, UI线程, 或新建新程.。

线程是协程的资源。协程通过Interceptor来间接使用线程这个资源。



选择协程, 显然是为了程序员友好, 更接近现实一点, 采用了异步机制, 将程序的逻辑流的控制权交给了程序员.

### 虚拟内存

虚拟内存是一个抽象概念, 它为每个进程提供了一个假象, 即每个进程都在独占地使用主存. 每个进程看到的内存都是一致的, 称为虚拟地址空间. 

在Linux中, 地址空间最上面的区域是保留给操作系统中的代码和数据的, 这对所有进程来说都是一样的, 地址空间的底部区域存放用户进程定义的代码和数据. 

![img](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426192157.png)

每个进程看到的虚拟地址空间由大量准确定义的区构成, 每个区都有专门的功能.

- 进程的虚拟地址空间
    - **程序代码和数据**. 代码和数据区是直接按照可执行目标文件的内容初始化的.
        - 代码和数据区在进程一开始运行时就被指定了大小.
    - **堆**. 运行时堆. 
        - 当调用标准库函数时, 堆可以在运行时动态地扩展和收缩.
    - 共享库. 大约在地址空间的中间部分是一块用来存放像C标准库和数学库这样的共享的代码和数据的区域
    - 栈. 用户栈, 编译器用它来实现函数调用. 
        - 用户栈在程序执行期间可以动态扩展和收缩.
        - <u>我们没调用一次函数时, 栈就会增长; 从一个函数返回时, 栈就会收缩</u>
    - 内核虚拟内存. 应用程序不被允许读写此区域的内容或直接调用内核代码定义的函数. 
        - 必须通过调用内核来执行这些操作.

### 文件

<u>文字就是字节序列, 仅此而已.</u>

每个I/O设备, 包括磁盘、键盘、显示器, 甚至网络, 都可以看成是文件. 

系统中的所有输入输出都是通过使用一小组称为Unix I/O的系统函数调用读写文件来实现的. 

文件这个简单而精致的概念是非常强大的, 因为它向应用程序提供了一个统一的试图, 来看待系统中可能含有的所有各式各样的I/O设备.  *统一了协议, 也就增加了兼容性*



### 系统之间利用网络通信

现代系统经常通过网络和其他系统连接到一起. 从一个单独的系统来看, 网络可视为一个I/O设备. 

当系统从主存复制一串字节到网络适配器时, 数据流经过网络到达另一台机器.

系统可以读取从其他机器发来的数据, 并把数据复制到自己的主存. 

### 阿姆达尔定律

>  amdahl's law

当我们对系统地某个部分加速时, 其对系统整体性能的影响取决于该部分的重要性和加速程度.

α: 系统部分执行时间比例

k: 系统部分性能提升比例

总执行时间: 
$$
T_{new} = (1-α)T_{old} + αT_{old}/k = T_{old}[(1-α) + α/k]
$$
加速比 $S =T_{old}/T_{new}$ 为
$$
S= \frac{1}{(1-α)+α/k}
$$
<u>主要观点: 想要显著加速整个系统, 必须提升全系统中相当大得部分的速度.</u> 



### 抽象的重要性

抽象的使用是计算机科学中重要的概念





# 信息的表示和处理

# 程序的机器级表示

## 控制

条件语句, 循环语句、和分支语句, 要求有条件的执行, 根据数据测试的结果来决定操作执行的顺序. 

机器代码提供两种基本的低级机制来实现有条件的行为: 测试数据值, 然后根据测试的结果来改变控制流或数据流.

jump指令肯依改变一组机器代码指令的执行顺序.



### for语句

```c
// for 循环
for (init_expr; text_expr; update_expr) {
    body_statement
}

// while 循环
init_expr;

while (test_expr) {
    body_statement;
    update_expr;
}

// 底层代码转换 - 跳转到中间策略
init_expr;
goto test;
loop:
	body_statement;
	update-expr;
test:
	t = text-expr;
	if (t)
        goto loop;

// 底层代码转换 - guarded-do 策略
init_expr;
t = test_expr;
if (!t)
    goto done;
loop:
	body_statement;
	update_expr;
	t = test_expr;
	if (t)
        goto loop;
done:
	next_expr;

```



## 过程-Procedures

> 代码片段集合

过程是软件中一种很重要的抽象. 它提供了一种封装代码的方式, 用一指定的参数和一个可选的返回值实现了某种功能. 然后, 可以在程序的不同地方调用这个过程. 

设计良好的软件用过程作为抽象机制, 隐藏某个行为的具体实现, 同时又提供清晰简洁的接口定义, 说明要计算的是哪些值, 过程会对程序状态产生什么影响. 

不同编程语言中, 过程的形式多样: 函数(function), 方法(method), 子例程(subroutine), 处理函数(handler)等, 但是他们有一些共有的特性. 

- 过程所具有的机制: 假设过程P调用过程Q, Q执行后返回到P
    - 转移控制(transfer control). 
    - 转移数据(transfer data). 传递参数, 返回值
    - 分配和释放内存(allocate and deallocate memory sapce). 

### 运行时栈-runtime stack

C语言过程调用机制的一个关键特性在于使用了栈数据结构提供的后进先出的内存管理原则. 

程序可以用栈来管理它的过程所需要的存储空间, 栈和程序寄存器存放存放着传递控制和数据、分配内存所需要的信息. 当P调用Q时, 控制和数据信息添加到栈尾. 当P返回时, 这些信息就会释放掉. 

栈向低地址方向增长, 而栈指针%rsp指向栈顶元素. 可以用pushq和popq指令将数据存入栈中或是从栈中取出. 将栈指针减小一个适当的量可以为没有指定初始值的数据在栈上分配空间. 类似地, 可以通过增加栈指针来释放空间.

当过程需要的存储空间超出寄存器能够存放的大小时, 就会在栈上分配空间. 这个个部分称为过程的栈帧(stack frame).

当前正在执行的过程的帧总是栈顶. 

### 转移控制-transfer control

# 优化程序性能

写程序的最主要目标就是使它在所有可能的情况下都**正确工作**. 零一个目标就是保证程序**高效运行**, 让程序运行得足够快. 

- 编写高效程序
    - 必须选择一组适当的算法和数据结构;
    - 必须编写出编译器能够有效优化以转换成高效可执行代码的源代码;
    - 运算量特别大得的计算, 将一个任务分成多个部分, 这些部分可以在多核和多处理器的某种组合上并行地计算. 
- 最佳实践
    - 减少过程调用
    - 消除不必要的内存引用
    - 循环展开:
        - 通过增加每次迭代计算的元素的数量, 减少循环的迭代次数
        - 减少了不直接有助于程序结果的操作的数量
        - 减少整个计算中关键路径上的操作数量
    - 提高并行性
    - 尽可能使用内置数据结构
- 一些限制因素
    - 寄存器移除
- 理解内存性能
- 确认和消除性能瓶颈



# 异常控制流

> exception control flow, ECF
>
> 对应《深入计算机操作系统》第8章

应用是如何与操作系统交互的. 这些交互都是围绕着ECF的.

在于一个计算机系统中所有层次上的各种形式的ECF.

从异常开始, 异常位于硬件和操作系统交界的部分. 我们还会讨论系统调用, 它们是为应用程序提供到操作系统地入口点的异常.

然后, 我们会提升抽象的层次, 描述进程和信号, 它们位于应用和操作系统的交界之处. 

最后讨论非本地跳转, 这是ECF的一种应用层形式. 

## 相关术语

> 另外参考 《计算机组成原理》



- **控制转移**(control transfer): PC将序列每次从$a_k$ 到$a_{k+1}$的过渡和切换. 

    - 从给处理器加电开始, 直到断电为止, 程序计数器假设一个值得序列

    - $$
        a_0, a_1 ..., a_{n-1}
        $$

    - 每个$a_k$是某个相应的指令$I_k$的地址

- **控制流**(control flow): 控制转移的序列$a_k$. 

    - 控制流默认是平滑的从 $I_k$ 到 $I_{k+1}$
    - 还可以通过跳转, 调用和返回等造成突变.
    - 以及异常控制流

- 系统还必须要能够对系统状态的变化做出反应, 这些系统状态不是被内部程序变量捕获的, 而且也不一定要和程序的执行相关.  如网路适配器接收包packet, 程序向磁盘请求数据, 子进程终止时通知父进程. 

- **异常控制流**(Exceptional Control Flow, ECF): 现代系统通过使控制流发生**突变**来对信号做出反应, 指这些突变

    - 控制流的.
    - 异常控制流发生在计算机系统地各个层次.
    - 在硬件层, 硬件检测到的事件会触发**控制**突然转移到异常处理程序. 
    - 在操作系统层, 内核通过上下文切换将**控制**从一个用户进程**转移**到另一个用户进程. 
    - 在应用层, 一个进程可以发送信号到另一个进程, 而接收者会将控制突然转移到它的一个信号处理程序.
    - 一个程序可以通过回避通常的栈规则, 并执行到其他函数中任意位置的非本地跳转来对错误做出反应. 

- 作为程序员, 理解ECF很重要, 这有很多原因:

    - 理解ECF将帮助你理解重要的系统概念.
    - 理解ECF将帮助你理解应用程序是如何与操作系统交互的. 
    - 理解ECF将帮助你编写有趣的新应用程序.
    - 理解ECF将帮助你理解并发.
    - 理解ECF将帮助你理解软件异常如何工作.软件异常允许程序进行**非本地跳转**(即违反通常的调用/返回栈规则的跳转)来响应错误情况. 非本地跳转是一种应用层ECF, 在C中是通过`setjmp`和`longjmp`函数提供的. 理解这些低级函数将帮助你理解高级软件异常如何得以实现.

- 进程控制块(Process Control Block, PCB), 操作系统核心中的一种数据结构, 主要表示进程状态.

- 进程状态: 可以是new、ready、running、waiting或blocked等。

- **程序计数器**(Program Counter，PC)：是一个中央处理器中的寄存器，用于指示计算机在其程序序列中的位置。接着要运行的指令地址。   *更多信息参考《计算机组成原理》*
  
    - 也称指令指针（instruction pointer，IP），有时又称为指令地址寄存器（instruction address register，IAR）、指令计数器或只是指令序列器的一部分。
    - 处理器通常从存储器中顺序获取指令，但控制转移指令(control transfer instruction)通过在PC中添加一个新值来改变顺序。这包括分支(跳转), 子程序调用和返回. 这让程序可以不同条件下执行不同的顺序.
    - PC在递增后获取一个指令(instruction), 并保存下一条将要执行的指令的内存地址。
    - 跳转从内存中的其他地方获取指令,
    - 子程序调用跳转并保存之前的PC指令内容到别处
    - 返回检索PC保存的内容并放回PC, 用子程序调用之后恢复顺序执行. 
    - 硬件实现: 指令周期(instruction cycle)从一个取值开始，在这个取值过程中，CPU把PC的值放在地址总线上，把它发送到内存中。
    - 指令周期: CPU取出并执行一条指令的时间, 不同指令的指令周期可能不同.



## 异常-Exception

异常是异常控制流的一种形式, 它一部分由硬件实现, 一部分由操作系统实现. 

对于每个系统而言, 基本的思想都是相同的. 

<u>异常就是控制流中的突变, 用来响应处理器状态中的某些变化(事件).</u>  

*异常是在控制转移的时候出现的*

状态变化称为事件(event). 事件可能和当前指令的执行直接相关. 比如虚拟内存缺页, 算术溢出.

在任何情况下, 当处理器检测到有事件发生时, 它就会通过一张叫做 **异常表**(exception table)的跳转表, 进行一个间接过程调用(异常), 到一个专门设计用来处理这类事件的操作系统子程序(异常处理程序(exception handler)). 

异常表是一张跳转表, 表目k包含异常k的处理程序代码的地址. 

```
当异常处理程序完成处理后, 根据引起异常的事件的类型, 会发生以下3种情况的一种: 

处理程序将控制返回给当前指令$I_{curr}$, 即当事件发生时正在执行的命令.
处理程序将控制返回给当前指令$I_{next}$, 如果没有发生异常将会执行的下一条指令.
处理程序终止被中断的程序.
```

### 异常处理

系统中可能的每种类型的异常都分配了一个唯一的非负整数的异常号(exception number), 包括处理器层级的, 操作系统内核的. 

在系统启动时, 操作系统分配和初始化一张称为异常表的跳转表, 使得表目k包含异常k的处理程序的地址.

在运行时, 处理器检测到发生了一个事件, 并且确定了相应的异常号k. 处理器触发异常, 方法是执行**间接过程调用**, 通过异常表的表目k, 转到相应的处理程序. 

异常号是异常表的索引, 异常表的起始地址放在一个叫做**异常表基址寄存器**(exception table base register)的特殊CPU寄存器里.

```
异常类似于过程调用, 但有一些重要的不同之处:

过程调用时, 在跳转到处理程序之前, 处理器将返回地址压如栈中. 然而, 根据异常的类型, 返回地址要么是当前指令, 要么是下一条指令;

处理器也把一些额外的处理状态压到栈里, 在处理程序返回时, 重新开始执行被中断的程序需要这些状态;

如果控制从用户程序转移到内核, 所有这些项目都被压到内核栈中, 而不是压到用户栈中;

异常处理程序运行在内核模式下, 意味着它们对所有的系统资源都有完全的访问权限.
```

一旦硬件触发了异常, 剩下的工作就是由异常处理程序在软件中完成. 在处理程序处理完成之后, 它通过执行一条特殊的"从中断返回"指令, 可选地返回到被中断的程序, 该指令将适当的状态弹回到处理器的控制和数据寄存器中, 如果一场中断的用户程序, 就将状态恢复为用户模式, 然后将控制返回给被中断的程序. 

### 异常的类型

异常可以分为四类: 中断(interrupt)、陷阱(trap)、故障(fault)和终止(abort). 

| 类别 | type      |       原因        | 异步/同步 |       返回行为       |
| :--: | --------- | :---------------: | :-------: | :------------------: |
| 中断 | interrupt | 来自I/O设备的信号 |   异步    | 总是返回到下一条指令 |
| 陷阱 | trap      |    有意的异常     |   同步    | 总是返回到下一条指令 |
| 故障 | fault     | 潜在可恢复的错误  |   同步    |  可能返回到当前指令  |
| 终止 | abort     |  不可恢复的错误   |   同步    |       不会返回       |

异步异常是由处理器外部的I/O设备中的时间产生的. 同步异常是执行一条指令的直接产物.

除了中断的异常类型(陷阱、故障和终止)是同步发生的, 是执行当前指令的结果. 我们把这类指令叫做故障指令(faulting instruction).

#### 中断-interrupt

中断是异步发送的, 是来自处理器外部的I/O设备的信号的结果. 硬件中断不是由任何一条专门的指令造成的, 从这个意义上来说它是异步的. 硬件中断的异常处理程序常常称为**中断处理程序**(interrupt handler). 

interrupt service routine(ISR), 中断处理程序被**硬件中断**, **软件中断指令**或**软件异常(software exceptions)**启动, 用于实现设备驱动程序或受保护操作模式间的转换, 比如系统调用.



发生中断异常后, 处理器直接将控制返回给下一条指令. 结果是程序继续执行, 就好像没有发生过中断一样. 



软件中断: 指令集中的指令或处理器自己的异常指令, 由软件调用, 用于与内核通信或调用系统调用, 尤其是错误和异常处理期间.



关于中断的场景:

[参考文档](https://www.techopedia.com/definition/22195/software-interrupt)

软件中断时, 应用程序终止或者从操作系统请求服务. 这和硬件中断区别很大, 硬件中断发生在硬件层的电平等低级别信号的变化. 中断仅仅会与内核通信并且间接地中断中央处理单元. 所有的软件中断都与中断处理程序(中断发生时的一个活跃的运行时)协同工作. 

通常的, 软件中断用于执行 I/O请求. 然后I/O请求反过来调用内核的运行时去执行服务.



#### 陷阱和系统调用-trap

陷阱是有意(故意/刻意设计)的异常, 是执行一条指令的结果. , 陷阱处理程序将控制返回到下一条指令. 

陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口, 叫做**系统调用**.

用户程序经常需要向内核请求服务, 比如 read, folk, exit. 为了允许对这些内核服务受控地访问, 处理器提供了一条特殊的"syscall n"指令, 当用户程序想要请求服务n时, 可以执行这条指令. 执行syscall指令会导致一个异常处理程序的陷阱, 这个处理程序解析参数, 并调用适当的内核程序. 

#### 故障-fault

故障是由错误引起的, 它可能能够被故障处理程序修正. 当故障发生时, 处理器将控制转移给故障处理程序. 

如果故障处理程序能够修正这个错误情况, 它就将控制返回到引起故障的指令, 从而重新执行它. 否则, 处理器返回到内核中的abort例程, abort例程会终止引起故障的应用程序. 

典型案例: 缺页, 发生故障时, 再次执行该指令时, 相应的物理页面就驻留在内存中了

#### 终止-abort

终止时不可恢复的指明错误造成的结果. 通常是一些硬件错误, 比如DRAM为被损坏时发生的奇偶错误. 

终止处理程序从不将控制返回给应用程序. 



## 进程-Process

> 运行时, 术语 

内核会自动调度每个进程, 每个进程有它自己的私有地址空间, 这使得逻辑流共享数据很困难

进程的经典定义: 一个执行中的程序**实例**. 系统中每个程序都运行在某个进程的上下文(context)中. 上下文是由程序正确运行所需的状态组成. 这个状态包括存放在内存中的程序的代码和数据, 它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述的集合. 

每次用户通过向shell输入一个可执行目标文件的名字, 运行程序时, shell就会创建一个新的进程, 然后在这个新进程的上下文中运行这个可执行目标文件. 应用程序也能创建新进程

### 逻辑控制流

**逻辑控制流**(control flow), 逻辑流: PC值得序列

如果想用调试器单步执行程序, 可以看到一系列PC的值, 这些值唯一地对应于包含在程序的可执行目标文件中的指令, 或是包含在运行时动态链接到程序的共享对象中的指令. 

每个进程维护一个逻辑流, 程序运行时, 进程逻辑流之间交替执行. 

每个进程执行它的逻辑流的一部分, 然后被抢占(preempted)(暂时挂起), 然后轮到其他进程. 

对于一个运行在这些进程之一的上下文中的程序, 看上去就是在独占的使用处理器. 

对于进程来讲, CPU似乎会周期性的停顿, 这是因为指令的执行间, 指令的调度需要消耗时间(指令周期)

### 并发流

**并发流**(concurrent flow):

定义: 一个逻辑流的执行在时间上与另一个流重叠

在计算机系统中逻辑流有许多不同的形式. 异常处理程序, 进程, 信号处理程序, 线程等. 

多个流并发地执行的一般现象称为 **并发(concurrency)**

**多任务**(multitasking): 一个进程和其他进程轮流运行

**时间片**(time slice): 一个进程执行它的控制流的一部分的每一时间段.

因此多任务也叫作**时间分片**(time slicing)

**并行流**(parallel flow): 两个流并发地运行在不同的处理器核或计算机上, 它们并行地运行(running parallel), 并且并行地执行(parallel execution).

用户模式和内核模式

为了使操作系统内核提供一个无懈可击的进程抽象, 处理器必须提供一种机制, 限制一个应用可以执行的指令以及它可以访问的地址空间范围. 

/proc文件系统:  允许用户模式进程访问内核数据结构的内容,  将许多内核数据结构的内容输出为一个用户程序可以读的文本文件层次结构.  使用该系统可以找出一般的系统属性比如/proc/cpuinfo.

/sys文件系统, 输出关于系统总线和设备的额外低层信息. 

用户程序必须通过系统调用接口间接地访问内核代码和数据. 

内核模式(superuser模式): 内核模式的进程可以执行指令集中的任何指令, 并且可以访问系统中的任何内存位置. 

### 私有地址空间

进程为每个程序提供它自己的私有地址空间

地址空间:  在一个64位地址的机器上, 地址空间是2的N次方个可能地址的集合.

一般而言, 和这个空间中某个地址相关联的哪个内存字节是不能被其他进程读或者写的, 从这个意义上说, 这个地址空间是私有的. 

地址空间底部是保留用户程序的, 包括通常的代码、数据、堆和栈段. 地址空间顶部保留给内核(操作系统常驻内存的部分). 地址空间的这个部分包含内核在代表进程执行指令时(比如执行系统调用时)使用的代码、数据和栈. 

![img](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426192214.png)

<img src="https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426192209.jpg" alt="img" style="zoom: 50%;" />

### 上下文切换(context switch)

操作系统内核使用一种称为上下文切换的较高层形式的**异常控制流**来实现多任务. 

上下文切换机制是建立在一般异常控制流机制值上的.

内核为每个进程维持一个上下文(context). 

<u>上下文就是内核重新启动一个被抢占的进程所需的状态.</u> 

它有一些对象的值组成, 这些对象包括通用目的寄存器、浮点寄存器、程序计数器、用户栈、状态寄存器、内核栈和各种内核数据结构, 比如描述地址空间的页表, 包含有关当前进程信息的进程表, 以及包含进程已打开文件的信息的文件表. 

在进程执行的某些时刻, 内核可以决定抢占当前进程, 并重新开始一个先前被抢占了的进程. 这种决策就叫做 **调度**(scheduling), 是由内核中称为调度器(scheduler)的代码处理的. 当内核选择了一个新的进程时, 我们说内核调度了这个进程. 

在内核调度了一个新的进程运行之后, 它就抢占当前进程, 并使用一种称为上下文切换的机制来讲控制转移到新的进程, 

```
上下文切换:

1)保存当前进程的上下文,  

2)恢复某个先前被抢占的进程被保存的上下文, 

3)将控制传递给这个新恢复的进程
```



当内核代表用户执行系统调用时, 可能会发生上下文切换. 如果系统调用因为等待某个时间发生而阻塞, 那么内核可以让当前进程休眠, 切换到零一个进程. 比如read文件操作, sleep操作等.



一般而言, 即使系统调用没有阻塞, 内核也可以选择执行上下文切换, 而不是将控制返回给调用进程.

*一个词之所以有多种描述, 是因为我们从不同的角度和层次去看待它的*

中断也可能引发上下文切换. 比如定时器, 每次发生定时器中断时, 内核就能判定当前进程已经运行了足够长的时间, 并切换到一个新的进程. 

*进程切换伴随着上下文切换, 或者说进程通过通过上下文切换机制进行切换*

### 系统调用错误处理

当Unix系统级

### 多进程

#### 1. 多进程优点

- 每个进程互相独立，不影响主程序的稳定性，子进程崩溃没关系；
- 通过增加CPU，就可以容易扩充性能；
- 可以尽量减少线程加锁/解锁的影响，极大提高性能，就算是线程运行的模块算法效率低也没关系；
- 每个子进程都有2GB地址空间和相关资源，总体能够达到的性能上限非常大

#### 2. 多进程缺点

- 逻辑控制复杂，需要和主程序交互；
- 需要跨进程边界，如果有大数据量传送，就不太好，适合小数据量传送、密集运算
- 多进程调度开销比较大；



## 系统调用错误处理

当Unix系统级函数遇到错误时, 它们通常会返回-1, 并设置全局整数变量errno来表示什么出错了. 

<u>程序员应该总是检查错误, 但是不幸的是, 许多人都忽略了错误检查, 因为它使代码变得臃肿, 而且难以读懂</u>

```c
if((pid = fork()) < 0) {
    fprint(stderr, "fork error: %s\n", strerror(errno));
    exit(0);
}
```

定义一个错误报告函数, 实现代码封装, 从而简化代码: 

```c
// 定义一个错误报告函数
void unix_error(char *msg) {
    fprint(stderr, "fork error: %s\n", strerror(errno));
    exit(0);
}
```

```c
// 简化后的代码
if ((pid = fork()) < 0) 
    unix_error("fork error");
```



通过使用**错误处理包装函数**, 我们可以进一步地简化代码.

对于一个给定的基本函数foo, 我们定义一个具有相同参数的包装函数Foo(首字母大写). 包装函数调用基本函数, 检查错误, 如果有任何问题就终止. 下面就是fork函数的错误处理包装函数:

```c
pid_t Fork(void) {
    pid_t pid;
    if ((pid = fork()) < 0)
        unix_error("fork error"):
    return pid;
}
```

```c
pid = Fork();  // 代码执行
```

错误处理包装函数能够保持代码间接, 而又不会给你错误的假象, 认为允许忽略错误检查. 

## 进程控制

Unix提供了大量从C程序中操作进程的系统调用. 下面是一些重要的函数并举例如何使用它们.

### 获取进程ID

### 创建和终止进程

### 回收子进程

### 僵尸进程(zombie/defunct)

在unix/linux操作系统中, 僵尸进程指执行完成(调用了exit系统调用命令, 或运行时发生致命错误或收到终止信号所致)时, 但是仍然存在于进程表中的进程控制块, 处于"终止状态(terminated state)"的进程. 这发生于[子进程](https://zh.wikipedia.org/wiki/子进程)需要保留表项以允许其[父进程](https://zh.wikipedia.org/wiki/父进程)读取子进程的[退出状态](https://zh.wikipedia.org/wiki/退出状态)：一旦退出态通过`wait`[系统调用](https://zh.wikipedia.org/wiki/系统调用)读取，僵尸进程条目就从进程表中删除，称之为"回收"（reaped）。正常情况下，进程直接被其父进程`wait`并由系统回收。进程长时间保持僵尸状态一般是错误的并导致[资源泄漏](https://zh.wikipedia.org/w/index.php?title=资源泄漏&action=edit&redlink=1)。



### 孤儿进程(Orphan Process)

孤儿进程指的是在其父进程执行完成或被终止后仍继续运行的一类进程。这些孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

因为父进程终止或崩溃都会导致对应子进程成为孤儿进程，所以也无法预料一个子进程执行期间是否会被“遗弃”。

### 程序与进程

程序是一堆代码和数据; 程序可以作为目标文件存在于磁盘上, 或者作为代码段存在于地址空间中.

进程时执行中程序的一个具体的实例; 程序总是运行在某个进程的上下文中.

fork函数在新的子进程中运行相同的程序, 新的子进程是父进程的一个复制品. 

execve函数在当前进程的上下文中加载并运行一个新的程序. 它会覆盖当前进程的地址空间, 但并没有创建一个新的进程, 新的程序仍然有相同的PID, 并且继承了调用execve函数时已经打开的所有文件描述符. 

### 进程间通信( , IPC)

> 7种方式: 管道, FIFO, 

- 管道
- 命名管道

- socket
- 消息队列
- 共享存储
- 信号量
- 信号

## 信号-signal

Linux信号, 一种更高层的软件形式的异常, 它允许进程和内核中断其他进程. 

**一个信号就是一条小消息**, 它通知进程系统中发生了一个某种类型的事件. 每种信号类型都对应于某种系统事件. 低层的硬件异常是由内核异常处理程序处理的, 正常情况下, 对用户进程而言是不可见的.

信号提供了一种机制, 通知用户进程发生了一些异常. 

### 信号术语

传送一个信号到目的进程是由两个不同步骤组成的:

**发送信号**. 内核通过更新目的进程上下文中的某个状态 , 发送一个信号给目的进程. 一个进程可以发送信号给自己.

**发送信号**. 当目的进程被内核强迫以某种方式对信号的发送做出反应时, 它就接收了信号. 进程可以忽略这个信号, 终止或通过执行一个称为**信号处理程序**(signal handler)的用户层函数捕获这个信号.





# 虚拟内存

为了更加有效地管理内存并且少出错, 现代系统提供了一种对主存RAM的抽象概念, 叫作虚拟内存(Virtual Memory, VM).

虚拟内存提供了三个重要的能力: 

1）它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。

2）它为每个进程提供了一致的地址空间，从而简化了内存管理。

3）它保护了每个进程的地址空间不被其他进程破坏。

虚拟内存是计算机系统最重要的概念之一。它成功的一个主要原因就是因为它是沉默地、自动地工作的，不需要应用程序员的任何干涉。

## 专业术语

- 物理地址计算机系统的主存被组织成一个由M个连续的字节大小的单元组成的数组每字节都有一个唯一的**物理地址**（Physical Address, PA）  物理寻址（physical  addressing)
- 早期的PC使用物理寻址。然而，现代处理器使用的是一种称为**虚拟寻址**（virtual addressing）的寻址形式.
- 使用虚拟寻址，CPU通过生成一个虚拟地址（ Virtual Address，VA）来访问主存，这个虚拟地址在被送到内存之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址的任务叫做地址翻译（address translation）。
    - 就像异常处理一样，地址翻译需要CPU硬件和操作系统之间的紧密合作。
    - CPU芯片上叫做内存管理单元（Memory Management Unit，MMU）的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。
- **地址空间**: 地址空间（address space）是一个非负整数地址的有序集合

### 虚拟内存作为缓存工具

- 概念上而言, 虚拟内存被组织为一个有放在磁盘上的N个连续的字节大小的单元组成数组.
- 没个字节都有一个唯一的虚拟地址, 作为到数组的索引.
- 磁盘上数组的内容被缓存在主存中. 
- VM系统通过将虚拟内存分割称为虚拟内存页(Virtual Page, VP)的大小固定的块

- 任意时刻, 虚拟页面的集合都分为三个不相交的子集:
    - 未分配的
    - 缓存的
    - 未缓存的
- 页表(page table), 数据结构, 将虚拟页映射到物理页.
- 页命中(缓存命中): 通过数组索引: 虚拟页找到物理页
- 缺页: DRAM缓存不命中
- 分配页面

### 虚拟内存作为内存管理的工具

# **程序间交互和通信**

# 系统级I/O

# 网络编程

# 并发编程

> 深入理解计算机系统 第12章
>
> Go 并发编程
>
> 并发编程三要素: 原子性, 可见性, 有序性
>
> 1. **原子性:** 一个不可再被分割的颗粒。原子性指的是一个或多个操作要么全部执行成功要么全部执行失败。
> 2. **有序性:** 程序执行的顺序按照代码的先后顺序执行。（处理器可能会对指令进行重排序）
> 3. **可见性:** 一个线程对共享变量的修改,另一个线程能够立刻看到。

并发(concurrency): 如果逻辑控制流在时间上重叠, 那么他们就是 并发的(concurrent).

这种常见的并发现象, 出现在计算机系统的许多不同层面上. 硬件异常处理程序、进程和Linux信号处理程序都是并发的. 

并发并不局限于内核, 它也可以在应用程序中扮演重要角色.

响应异步事件用户键入 `⌃C` 

使用应用级并发的应用程序称为 **并发程序(concurrent program)**.

## 核心概念

- 逻辑流: 
- 文件描述符(file descriptor): 
    - 内核(kernel)利用文件描述符来访问文件.



## 并发应用场景

- 访问慢速I/O设备;
    - 当一个应用在等待来自慢速I/O设备(例如磁盘)的数据到达是时, 内核会运行其他进程, 使CPU保持繁忙. 
    - 应用通过交替执行I/O请求和其他有用的工作来利用并发. 
- 与人交互; 
    - 和计算机交互的人要求计算机有同时执行多个包任务的能力. 
- 通过推迟工作以降低延迟; 
    - 应用程序能够通过推迟其他操作和并发地执行它们, 利用并发来降低某些操作的延迟. 
    - *推迟不重要的任务, 为优先任务提供更多资源*
- 服务多个网络客户端; 
    - 迭代网络服务器是不现实的, 这样一次只能为一个客户端提供服务.
    - 一个慢速的客户端可能会导致服务器拒绝为所有其他客户端服务. 
    - 一个更好的方法是创建一个并发服务器, 它为每个客户端创建一个单独的逻辑流.
    - 这允许服务器同时为多个客户端服务, 并且也避免了慢速客户端独占服务器. 
- 在多核机器上进行并行计算; 
    - 多核处理器其实表示多个CPU处理器, 核(chip, core).
    - 被划分成并发流的应用程序通常在多核机器上比在单核处理器上运行得快
    - 控制流在多核上并行执行, 而不是交错执行.

## 构造并发程序方法

- 进程.
    - 每个逻辑控制流都是一个进程, 由内核来调度和维护. 
    - 进程有独立的虚拟地址空间, 想要和其他流通信, 控制流必须使用某种显式的进程间通信机制(interprocess communication, IPC)机制
- I/O多路复用.
    - 这种形式的并发编程, 应用程序在一个进程的上下文中显式地调度它们自己的逻辑流
    - 逻辑流被模型化为状态机, 数据到达文件描述后, 主程序显式地从一个状态转换为另一个状态.
    - 程序是一个单独的进程, 所有的流都共享同一个地址空间.
- 线程; 
    - 线程是运行在一个单一进程上下文中的逻辑流, 由内核进行调度. 
    - 线程像进程或流一样由内核进行调度. 线程像逻辑流一样共享同一个虚拟地址空间.

## 基于进程的并发编程

构造并发程序最简单的方法就是用进程, 相关函数`fork`, `exec`和 `waitpid`.

构造一个并发服务器的自然方法是, 父进程中接收客户端连接请求, 然后创建一个新的子进程来为每个新客户端服务.

>  服务器监听一个监听描述符上的连接请求, 接收连接请求后, 服务器派生一个子进程, 这个子进程获得服务器描述符表的完整副本.

### 进程的优点

> [参考文档](https://cloud.tencent.com/developer/article/1416283)

对于在父, 子进程间共享状态信息, 进程有一个非常清晰地模型; 共享文件表, 但是不共享用户地址空间. 进程有独立的地址空间既是优点也是缺点. 

优点: 进程有各自的地址空间, 不共享虚拟内存, 一个进程维护一块虚拟内存.

- 顺序程序的特点：具有封闭性和可再现性；
- 程序的并发执行和资源共享。多道程序设计出现后，实现了程序的并发执行和资源共享，提高了系统的效率和系统的资源利用率。

### 缺点

独立的地址空间使得进程共享状态信息变得更加困难. 为了共享信息, 必须使用显式的IPC机制. 基于进程的设计的另一个缺点是, 它们往往比较慢, 因为进程控制和IPC的开销很高. 

- 操作系统调度切换多个线程要比切换调度进程在速度上快的多。而且进程间内存无法共享，通讯也比较麻烦。
- 线程之间由于共享进程内存空间，所以交换数据非常方便；在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。

## 基于I/O多路复用的并发编程

> 单线程或单进程同时监测若干个文件描述符是否可以执行IO操作的能力。

I/O多路复用(I/O multiplexing)技术. 基本思路是使用select函数, 要求内核挂起进程, 只有在一个或多个I/O时间发生后, 才将控制返回给应用程序. 

fd : file descriptor 文件描述符

```c
#include <sys/select.h>

int select(int n, fd_set *fdset, NULL, NULL, NULL);  // 返回已准备好的描述符的非零的个数,若出错则为-1

FD_ZERO(fd_set*fdset);/* Clear all bits in fdset*/ 
FD_CLR(int fd, fd_set *fdset);/* Clear bit fd in fdset*/
FD_SET(int fd,fd_set*fdset);/* Turn on bit fd in fdset*/
FD_ISSET(int fd, fd_set *fdset); /* Is bit fd in fdset on? */
//处理描述符集合的宏。
```



select 函数处理类型为fd_set的集合, 也叫描述符集合. 逻辑上, 我们将描述符集合看成一个大小为n的位向量:
$$
b_{n-1}, ... , b_1, b_0
$$
每个位$b_k$对应于描述符$k$. 当且仅当$b_k=1$, 描述符k才表明是描述符集合的一个元素. 只允许你对描述符集合做三件事: 1)分配它们, 2)将一个此种类型的变量赋值给另一个变量, 3)用FD_ZERO、FD_SET、FD_CLR、FD_ISSET宏来修改和检查它们.

针对我们的目的, select函数有两个输入: 一个称为**读集合**的描述符集合(fdset), 该读集合的基数n(实际上是任何描述符集合的最大基数) *基数: 集合的个数*

select函数会一直阻塞, 直到读集合中至少有一个描述符准备好可以读. 当且仅当一个从该描述符读取一个字节的请求不会阻塞时, 描述符k就表示准备好可以读了. 

select函数有一个副作用, 它修改fdset指向的fd_set, 指明(*指代, 表示*)读集合的一个子集, 称为准备好集合(ready set), 这个集合是由读集合中准备好可以读了的描述符组成的. 该函数返回的值指明了准备好集合的基数.

*返回的值是 准备好的集合的基数, 是变化的, 相同的输入, 每次调用返回的值不确定一样, 所以有副作用* 

<u>注意, 由于这个副作用, 我们必须在每次调用select时都更新读集合</u>



```c
while (1) {
    select( listenfd+1, &ready_set, NULL, NULL, NULL); //listenfd 侦听描述符
    if A;
    if B;
    // 不断调用迭代select函数, 每次调用时都更新一次&ready_set 
}
// 等待侦听描述符上的连接请求和标准输入上的命令
```



### 基于I/O多路复用的并发事件驱动服务器

在事件驱动程序中, 某些事件会导致流向前推进.

一般思路是将逻辑流模型转化为状态机.

不严格地说, 一个状态机(state machine)就是一组状态(state)、输入事件(input event)和转移(transition); 其中转移是将状态和输入事件映射到状态.

每个转移是将一个(输入状态, 输入事件)对 映射到一个输出状态.

自循环(self-loop)是同一输入和输出状态之间的转移.

通常把状态机画成有向图, 其中节点表示状态, 有向弧表示转移, 而弧上的标号表示输入事件.

一个状态机从某种初始状态开始执行. 每个输入事件都会引发一个从当前状态到下一状态的转移.

服务器使用I/O多路复用, 借助select函数检测输入事件的发生. 当每个已连接描述符准备好可读时, 服务器就为相应的状态机执行转移, 在这里就是从描述符读和写回一个文本行.

### I/O多路复用技术的优劣

相比进程模型, 程序员对程序行为有更多的控制. 而且运行在单一进程上下流中, 因此每个逻辑流都能访问该进程的全部地址空间. 这使得每个逻辑流都能访问该进程的全部地址空间.

耽搁进程也更方便调试, 就像是顺序程序一样. 

事件驱动设计常常比基于程序的设计要高效得多, 因为它们不需要进程上下文切换来调度新的流. 



明显的缺点是, 编码复杂. 

只要某个逻辑流正忙于读一个文本行, 其他逻辑流就不可能有进展(I/O)阻塞. 



## 基于线程的并发编程

> posix线程

进程由内核自动调度逻辑流, 每个进程有它自己的私有地址空间;

I/O多路复用技术则是程序员创建自己的逻辑流并显式地调用.

线程则是这两种方法的混合.



<u>**线程**(thread)就是运行在进程上下文中的逻辑流.</u> 

线程由内核自动调度. 每个线程都有它自己的线程上下文(thread context), 包括一个唯一的整数线程ID、栈、栈指针、程序计数器、通用目的寄存器和条件码. 

所有的运行在一个进程里的线程共享该进程的整个虚拟地址空间. 



内核通过一个整数ID来识别线程. 

同基于I/O多路复用的流一样, 多个线程运行在单一进程的上下文中, 因此共享这个进程虚拟地址空间的所有内容, 包括它的代码、数据、堆、共享库和打开的文件. 

### 多线程执行模型

上下文切换需要消耗时间

每个进程开始声明周期时都是单一线程, 这个线程称为主线程(main thread).

在某一时刻, 主线程创建一个对等线程(peer thread), 从这个时候开始, 两个线程就并发的运行.



因为主线程执行一个慢速系统调用, 例如read或者sleep, 或者因为被系统的间隔计时器中断, 控制就会通过上下文切换传递到对等线程. 

对等线程会执行一段时间, 然后控制传递会主线程, 以此类推.

一个线程的上下文要比一个进程的上下文小得多, 线程上下文的切换要比进程的上下文切换快得多. 

线程不想进程那样, 不是按照严格的父子层次来组织的. 

和一个进程相关的线程组成一个对等(线程)池, 独立于其它线程创建的线程. 

主线程和其他线程的区别仅在于它总是进程中第一个运行的线程. 

对等(线程)池概念的主要影响是, 一个线程可以杀死它的任何对等线程, 或者等待它的任意对等线程终止. *子线程的控制由主线程决定*

另外每个对等线程都能读写相同的共享数据. 

### POSIX线程

POSIX线程(Pthreads)是在C程序中处理线程的一个标准接口.

线程例程(thread routine): 封装线程代码和本地数据的函数对象, 用于创建线程是的参数传入. 传递参数时, 采用一个人结构传入. 

```c
#include "csapp.h"

void *threas(void *vargp);

int main(){
    pthread_t tid;
    Pthread_create(&tid, NULL, thread, NULL);
    Pthread.join(tid, NULL);
    exit(0);
}

void *thread(void *vargp) {
    printf("Hello, world!\n");
    return NULL;
}
```

join函数会阻塞主线程, 直到指定的线程运行结束为止



## 多线程程序中的共享变量

线程的基础内存模型是什么?

变量实例是如何映射到内存的?

多少线程应用这些实例?

### 线程内存模型

一组并发线程运行在一个进程的上下文中. 

每个线程都有它自己独立的线程上下文化, 包括线程ID、栈、栈指针、程序计数器、条件码和通用目的的寄存器值. 

每个线程和其他线程一起共进程上下文的剩余部分. 

线程也共享相同的打开文件的集合. 

## 用信号量同步线程

> 共享变量十分方便, 但是也容易因为抢zhan

## 使用线程提高并行性

## 其他并发问题

同步技术:

互斥

生产者-消费者同步技术

### 线程安全

> 并发执行时造成的不同步问题. 比如涉及到读写问题时, 需要加锁, 否则出现脏读, 幻读等现象. 

一个函数被称为线程安全(thread-safe), 当且仅当被多个并发线程函数反复地调用时, 它会抑制产生正确的结果. *不会产生副作用*

有四类线程不安全函数类:

<u>第一类: 不保护共享变量的函数.</u> 如对全局共享变量加1操作

<u>第2类: 保持跨越对个调用的状态的函数.</u> 其实也是对全局变量的引用, 有其他变量对其进行修改. 

<u>第3类: 返回指向静态变量的指针的函数.</u>  消除共享数据, 加速-复制

<u>第4类: 调用线程不安全函数的函数.</u> 



在线程化的程序中使用已存在的库函数, 一般Linux系统针对线程不安全版本都提供了线程安全函数 以 `*_r`标识. 如 `rand` 函数的线程安全函数版本是 `rand_r`

```c
unsigned next_seed = 1;

unsigned rand(void) {
    next_seed = next_seed * 1103515245 + 12543;
    return (unsigned)(next_seed>>16) % 32768;
}

void srand(unsigned new_seed) {
    next_seed = new_seed
}
```



### 竞争-race



单核一个程序的正确性依赖于一个线程要在另一个线程到达y点之前, 到达该线程的的控制流中的x点时, 就会发生竞争(race). 

通常发生精致是因为程序员假定线程将按照某种特殊的轨迹线执行状态空间, 而忘记了另一条规则: 多线程的程序必须对任何可行的轨迹线都正确工作. 

*主线程和对等线程之间的竞争, 一般主线程要用于线程管理, 会消耗时间*

### 死锁

信号量引入了一种潜在的令人厌恶的运行时错误, 叫做死锁(deadlock), 它指的是一组线程被阻塞了, 等待一个永远也不会为真的条件. 




## 处理高并发的方案

> [参考文档1](https://blog.csdn.net/kang1011/article/details/88659465)
>
> [参考文档2](https://blog.csdn.net/qq_36929638/article/details/101102230?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control)
>
> 方法
>
> 1. **原子性:** 一个不可再被分割的颗粒。原子性指的是一个或多个操作要么全部执行成功要么全部执行失败。
> 2. **有序性:** 程序执行的顺序按照代码的先后顺序执行。（处理器可能会对指令进行重排序）
> 3. **可见性:** 一个线程对共享变量的修改,另一个线程能够立刻看到。

1：系统拆分，将一个系统拆分为多个子系统，用dubbo来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，这样就可以抗高并发。

2：缓存，必须得用缓存。大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家redis轻轻松松单机几万的并发啊。没问题的。所以你可以考的虑考虑你的项目里，那些承载主要请求读场景，怎么用缓存来抗高并发。

3：MQ(消息队列)，必须得用MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，人家是缓存你要是用redis来承载写那肯定不行，数据随时就被LRU(淘汰掉最不经常使用的)了，数据格式还无比简单，没有事务支持。所以该用mysql还得用mysql啊。那你咋办？用MQ吧，大量的写请求灌入MQ里，排队慢慢玩儿，后边系统消费后慢慢写，控制在mysql承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用MQ来异步写，提升并发性。MQ单机抗几万并发也是ok的。

4：分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来抗更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高sql跑的性能。

5：读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。

# 零散待整理



# 线程

## 1. 线程的优点

- 它是一种非常”节俭”的多任务操作方式。在Linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种”昂贵”的多任务工作方式。而运行于一个进程中的多个线程，它们彼此之间使用相同的地址空间，共享大部分数据，启动一个线程所花费的空间远远小于启动一个进程所花费的空间，而且，线程间彼此切换所需的时间也远远小于进程间切换所需要的时间。当然，在具体的系统上，这个数据可能会有较大的区别；
- 线程间方便的通信机制，由于同一进程下的线程之间共享数据空间，所以一个线程的数据可以直接为其它线程所用，这不仅快捷，而且方便；

使多CPU系统更加有效。操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上；

## 2. 线程的缺点

- 调度时, 要保存线程状态，频繁调度, 需要占用大量的机时；
- 程序设计上容易出错（线程同步问题）。

# 多线程

## 1. 多线程的优点

- 无需跨进程边界；
- 程序逻辑和控制方式简单；
- 所有线程可以直接共享内存和变量等；
- 线程方式消耗的总资源比进程方式好；

## 2. 多线程缺点

- 每个线程与主程序共用地址空间，受限于2GB地址空间；
- 线程之间的同步和加锁控制比较麻烦；
- 一个线程的崩溃可能影响到整个程序的稳定性；
- 到达一定的线程数程度后，即使再增加CPU也无法提高性能，例如Windows Server 2003，大约是1500个左右的线程数就快到极限了（线程堆栈设定为1M），如果设定线程堆栈为2M，还达不到1500个线程总数；
- 线程能够提高的总性能有限，而且线程多了之后，线程本身的调度也是一个麻烦事儿，需要消耗较多的CPU

